1. **Llama 3.1 Model Card**: This document details Llama 3.1, an autoregressive language model utilizing an optimized transformer architecture.  
   [https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md](https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md)

2. **Llama 3 Model Card**: This card provides information on the Llama 3 family, which includes models with 8B and 70B parameters in both pre-trained and instruction-tuned variants.  
   [https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md](https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md)

3. **Llama 3.2 Model Card**: This document outlines Llama 3.2, an autoregressive language model with an optimized transformer architecture.  
   [https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md)

4. **Llama 2 Model Card**: This card discusses the Llama 2 models, available in parameter sizes of 7B, 13B, and 70B, in both pre-trained and fine-tuned variations.  
   [https://github.com/Meta-Llama/llama/blob/main/MODEL_CARD.md](https://github.com/Meta-Llama/llama/blob/main/MODEL_CARD.md)